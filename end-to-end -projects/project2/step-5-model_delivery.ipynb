{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:42px; text-align:center; margin-bottom:30px;\"><span style=\"color:SteelBlue\">Step 5:</span> The Delivery</h1>\n",
    "<hr>\n",
    "\n",
    "Now, we'll show you how you can use your model to predict brand new (**raw**) data and package your work together into an executable script.\n",
    "\n",
    "\n",
    "Essential steps of project delivery:\n",
    "\n",
    "1. [Confirm your model was saved correctly](#confirm)\n",
    "2. [Write pre-modeling functions](#pre-model)\n",
    "3. [Construct a model class](#model-class)\n",
    "4. [Method 1: Jupyter notebook](#jupyter)\n",
    "5. [Method 2: Executable script](#exectuable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing ze libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Pickle for reading model files\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import shortcut function <code style=\"color:steelblue\">roc_auc_score()</code> for **area under ROC curve** metric\n",
    "- for verification no need to plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Area under ROC curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load our winning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final_model.pkl as model\n",
    "with open('final_model/project2_final_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Confirm our model was saved correctly\n",
    "\n",
    "quick sanity to check we are proceeding with the correct model.\n",
    "\n",
    "**Firstly, Confirming a few key details:**\n",
    "* It should be a model <code style=\"color:steelblue\">Pipeline</code>.\n",
    "* Features should be scaled \n",
    "    * The first step should have a <code style=\"color:steelblue\">StandardScaler</code> preprocessing step.\n",
    "*  Type of model should also be appropriate\n",
    "    * in this case a <code style=\"color:steelblue\">RandomForestClassifier</code> model.\n",
    "    \n",
    "**Then, verifying our model is indeed correct**....\n",
    "Methodology:\n",
    "\n",
    "1. Load the original analytical base table (ABT) that was used to train the model.\n",
    "2. Split it into the same training and test sets (with the same random seed).\n",
    "3. See if we get the same AUROC on the test set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model object\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Feature scaled: check.\n",
    "2. Random Forest model: check.\n",
    "\n",
    "**Let's see if the model replicates (matches) in score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load analytical base table used in Module 4\n",
    "abt = pd.read_csv('project_files/analytical_base_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**split it into training and test sets**\n",
    "* remember to stratify the data <code style=\"color:steelblue\">stratify = (data).status</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create separate object for target variable\n",
    "y = abt.status\n",
    "# Create separate object for input features\n",
    "X = abt.drop('status', axis=1)\n",
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction of our model, and printing the <code style=\"color:steelblue\">roc_auc_score</code>.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict X_test\n",
    "pred = model.predict_proba(X_test)\n",
    "# Get just the prediction for the postive class (1)\n",
    "pred = [p[1] for p in pred]\n",
    "# Print AUROC\n",
    "score = roc_auc_score(y_test, pred)\n",
    "print('AUROC', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the same one, we are good to go. One last thing:\n",
    "\n",
    "Let's load some brand new, **raw data** that we've never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('project_files/unseen_raw_data.csv')\n",
    "\n",
    "print( raw_data.shape )\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When we try to apply our model to this raw dataset, we'll get an error.**\n",
    "\n",
    "How could we make it so our model works for any random raw dataset of same configuration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write pre-modeling functions\n",
    "\n",
    "Writing a function to automatically **convert the raw data to the same format as the analytical base table**.\n",
    "That is encapsulating our code from Step 2 : ABT construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Drop temporary workers\n",
    "    df = df[df.department != 'temp']\n",
    "    \n",
    "    # Missing filed_complaint values should be 0\n",
    "    df['filed_complaint'] = df.filed_complaint.fillna(0)\n",
    "\n",
    "    # Missing recently_promoted values should be 0\n",
    "    df['recently_promoted'] = df.recently_promoted.fillna(0)\n",
    "    \n",
    "    # 'information_technology' should be 'IT'\n",
    "    df.department.replace('information_technology', 'IT', inplace=True)\n",
    "\n",
    "    # Fill missing values in department with 'Missing'\n",
    "    df['department'].fillna('Missing', inplace=True)\n",
    "\n",
    "    # Indicator variable for missing last_evaluation\n",
    "    df['last_evaluation_missing'] = df.last_evaluation.isnull().astype(int)\n",
    "    \n",
    "    # Fill missing values in last_evaluation with 0\n",
    "    df.last_evaluation.fillna(0, inplace=True)\n",
    "    \n",
    "    # Return cleaned dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how well our function cleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a clean_data \n",
    "cleaned_data = clean_data(raw_data)\n",
    "# Display first 10 observations\n",
    "cleaned_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data is clean still need to alter our features. \n",
    "the function <code style=\"color:steelblue\">engineer_features()</code> encapsulates all of the feature engineering steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    # Create indicator features\n",
    "    df['underperformer'] = ((df.last_evaluation < 0.6) & \n",
    "                            (df.last_evaluation_missing == 0)).astype(int)\n",
    "\n",
    "    df['unhappy'] = (df.satisfaction < 0.2).astype(int)\n",
    "\n",
    "    df['overachiever'] = ((df.last_evaluation > 0.8) & (df.satisfaction > 0.7)).astype(int)\n",
    "        \n",
    "    # Create new dataframe with dummy features\n",
    "    df = pd.get_dummies(df, columns=['department', 'salary'])\n",
    "    \n",
    "    # Return augmented DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new DataFrame named <code style=\"color:steelblue\">augmented_data</code> that is both clean & engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented_data\n",
    "augmented_data = engineer_features(clean_data)\n",
    "# Display first 5 rows\n",
    "augmented_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our raw data has now been transformed into clean & engineered data (super f***** cool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"model-class\">\n",
    "# 3. Construct a class for our model\n",
    "\n",
    "packaging these functions together into a **model class**. \n",
    "\n",
    "Convenient way to keep all of the logic for a given model in one place.\n",
    "- Include logic for cleaning data, feature engineering, and predicting new observations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmployeeRetentionModel:\n",
    "    \n",
    "    def __init__(self, model_location):\n",
    "        with open(model_location, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "    \n",
    "    def predict_proba(self, X_new, clean=True, augment=True):\n",
    "        if clean:\n",
    "            X_new = self.clean_data(X_new)\n",
    "        \n",
    "        if augment:\n",
    "            X_new = self.engineer_features(X_new)\n",
    "        \n",
    "        return self.model.predict_proba(X_new)\n",
    "    \n",
    "    \n",
    "    def clean_data(self, df):\n",
    "        # Drop duplicates\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        # Drop temporary workers\n",
    "        df = df[df.department != 'temp']\n",
    "\n",
    "        # Missing filed_complaint values should be 0\n",
    "        df['filed_complaint'] = df.filed_complaint.fillna(0)\n",
    "\n",
    "        # Missing recently_promoted values should be 0\n",
    "        df['recently_promoted'] = df.recently_promoted.fillna(0)\n",
    "\n",
    "        # 'information_technology' should be 'IT'\n",
    "        df.department.replace('information_technology', 'IT', inplace=True)\n",
    "\n",
    "        # Fill missing values in department with 'Missing'\n",
    "        df['department'].fillna('Missing', inplace=True)\n",
    "\n",
    "        # Indicator variable for missing last_evaluation\n",
    "        df['last_evaluation_missing'] = df.last_evaluation.isnull().astype(int)\n",
    "\n",
    "        # Fill missing values in last_evaluation with 0\n",
    "        df.last_evaluation.fillna(0, inplace=True)\n",
    "\n",
    "        # Return cleaned dataframe\n",
    "        return df\n",
    "        \n",
    "    def engineer_features(self, df):\n",
    "        # Create indicator features\n",
    "        df['mediocre'] = ((df.last_evaluation < 0.6) & \n",
    "                                (df.last_evaluation_missing == 0)).astype(int)\n",
    "\n",
    "        df['frustrated'] = (df.satisfaction < 0.2).astype(int)\n",
    "\n",
    "        df['ambitious'] = ((df.last_evaluation > 0.8) & (df.satisfaction > 0.7)).astype(int)\n",
    "\n",
    "        # Create new dataframe with dummy features\n",
    "        df = pd.get_dummies(df, columns=['department', 'salary'])\n",
    "\n",
    "        # Return augmented DataFrame\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"jupyter\"></span>\n",
    "# 4. Method 1: Jupyter notebook\n",
    "\n",
    "2 simplest ways to deploy our model.\n",
    "1. Keep it in Jupyter Notebook\n",
    "2. Port it to an executable script\n",
    "\n",
    "For jupyer notebook:\n",
    "First, simply initialize an instance of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an instance\n",
    "retention_model = EmployeeRetentionModel('final_model/project2_final_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If implemented correctly, these next three statements should all work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict raw data\n",
    "_, pred1 = retention_model.predict_proba(raw_data, clean=True, augment=True)\n",
    "\n",
    "# Predict cleaned data\n",
    "_, pred2 = retention_model.predict_proba(cleaned_data, clean=False, augment=True)\n",
    "\n",
    "# Predict cleaned and augmented data\n",
    "_, pred3 = retention_model.predict_proba(augmented_data, clean=False, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:steelblue\">_, pred1 =</code> simply means we're throwing away the first object that's returned (which was <code style=\"color:steelblue\">X_new</code>).\n",
    "\n",
    "Their predictions should all be equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be true\n",
    "np.array_equal(pred1, pred2) and np.array_equal(pred2, pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"executable\"></span>\n",
    "# 5. Method 2: Executable script (optional)\n",
    "\n",
    "An example script in the <code style=\"color:crimson\">project_files/</code> directory of this project called <code style=\"color:crimson\">retention_model.py</code>.\n",
    "\n",
    "To run the script, call it from the command line:\n",
    "\n",
    "<pre style=\"color:crimson; margin-bottom:30px\">\n",
    "EDS:step-5-model_delivery - Project Delivery EDS$ python project_files/retention_model.py project_files/unseen_raw_data.csv predictions.csv final_model.pkl True True\n",
    "</pre>\n",
    "\n",
    "This'll save a new file that includes the predictions. It'll looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will only work after running the command above\n",
    "predictions = pd.read_csv('predictions.csv')\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Essential steps to professionally deliver the model:\n",
    "* Duplicate and confirm your model was saved correctly.\n",
    "* Compile data cleaning and feature engineering functions we used in ABT construction\n",
    "* Package everything together (our logic) in a custom model class.\n",
    "* Apply your model to raw data in Jupyter Notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
