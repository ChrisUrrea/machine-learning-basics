{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:42px; text-align:center; margin-bottom:30px;\"><span style=\"color:SteelBlue\">Step 4:</span> Model Training</h1>\n",
    "\n",
    "Essential 3 steps completed steps leading up to training our model: \n",
    "1. Exploratory Analysis\n",
    "2. Data Cleaning\n",
    "3. Feature Engineering\n",
    "\n",
    "\n",
    "The essential modeling and training steps:\n",
    "\n",
    "1. [Split our dataset](#split)\n",
    "2. [Build model pipelines](#pipelines)\n",
    "3. [Declare hyperparameters to tune](#hyperparameters)\n",
    "4. [Fit and tune models with cross-validation](#fit-tune)\n",
    "5. [Evaluate metrics](#evaluate)\n",
    "6. [Area under ROC curve](#auroc)\n",
    "\n",
    "Again, we'll split the dataset, set up pipelines, declare hyperparameters, and tune models using cross-validation. We'll use area under ROC curve as the performance metric for our classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Pickle for saving model files\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the algorithms and all the other good things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Import RandomForestClassifier and GradientBoostingClassifer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# For standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get our analytical base table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analytical base table from Module 2\n",
    "abt = pd.read_csv('project_files/analytical_base_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y object for target variable\n",
    "y = abt['status']\n",
    "\n",
    "# X object for input features\n",
    "X = abt.drop('status', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Important:** We pass in the argument <code style=\"color:steelblue\">stratify =<span style=\"color:crimson\"> y</code> in order to make sure the target variable's classes are balanced in each subset of data! This is **stratified random sampling**.\n",
    "* Then, print the number of observations in each subset to check that it was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254 2814 11254 2814\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build our model pipelines\n",
    "\n",
    "Set up preprocessing pipelines for each of our algorithms.\n",
    "\n",
    "**Our <span style=\"color:royalblue\">pipeline dictionary</span> with pipelines for each algorithm**. \n",
    "\n",
    "**KEYS**:\n",
    "* <code style=\"color:crimson\">'l1'</code> for $L_1$-regularized logistic regression\n",
    "* <code style=\"color:crimson\">'l2'</code> for $L_2$-regularized logistic regression\n",
    "* <code style=\"color:crimson\">'rf'</code> for random forest\n",
    "* <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "\n",
    "Note: Each pipeline tandardizes the data first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline dictionary\n",
    "pipeline = {'l1' : make_pipeline(StandardScaler(), LogisticRegression(penalty='l1')),\n",
    "            'l2' : make_pipeline(StandardScaler(), LogisticRegression(penalty='l2')),\n",
    "            'rf' : make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "            'gb' : make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Declare hyperparameters to tune\n",
    "\n",
    "**listing hyperparameters to be tuned for each of our algorithms in the pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))], 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 100, 'logisticregression__multi_class': 'ovr', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l1', 'logisticregression__random_state': None, 'logisticregression__solver': 'liblinear', 'logisticregression__tol': 0.0001, 'logisticregression__verbose': 0, 'logisticregression__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 'L1' hyperparamters\n",
    "print(pipeline['l1'].get_params())\n",
    "l1_hyperparameters = {'logisticregression__C': np.linspace(1e-3,1e3,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))], 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 100, 'logisticregression__multi_class': 'ovr', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', 'logisticregression__random_state': None, 'logisticregression__solver': 'liblinear', 'logisticregression__tol': 0.0001, 'logisticregression__verbose': 0, 'logisticregression__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 'L2' hyperparameters\n",
    "print(pipeline['l2'].get_params())\n",
    "l2_hyperparameters = {'logisticregression__C': np.linspace(1e-3,1e3,10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare the hyperparameter grid for the random forest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))], 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'randomforestclassifier': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'randomforestclassifier__bootstrap': True, 'randomforestclassifier__class_weight': None, 'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_impurity_decrease': 0.0, 'randomforestclassifier__min_impurity_split': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 10, 'randomforestclassifier__n_jobs': 1, 'randomforestclassifier__oob_score': False, 'randomforestclassifier__random_state': None, 'randomforestclassifier__verbose': 0, 'randomforestclassifier__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest hyperparameters\n",
    "print(pipeline['rf'].get_params())\n",
    "rf_hyperparameters = {'randomforestclassifier__n_estimators': [100,200,300],  'randomforestclassifier__max_features': ['sqrt','auto','log2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare the hyperparameter grid for the boosted tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingclassifier', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False))], 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'gradientboostingclassifier': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'gradientboostingclassifier__criterion': 'friedman_mse', 'gradientboostingclassifier__init': None, 'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__loss': 'deviance', 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__max_features': None, 'gradientboostingclassifier__max_leaf_nodes': None, 'gradientboostingclassifier__min_impurity_decrease': 0.0, 'gradientboostingclassifier__min_impurity_split': None, 'gradientboostingclassifier__min_samples_leaf': 1, 'gradientboostingclassifier__min_samples_split': 2, 'gradientboostingclassifier__min_weight_fraction_leaf': 0.0, 'gradientboostingclassifier__n_estimators': 100, 'gradientboostingclassifier__presort': 'auto', 'gradientboostingclassifier__random_state': None, 'gradientboostingclassifier__subsample': 1.0, 'gradientboostingclassifier__verbose': 0, 'gradientboostingclassifier__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Boosted Tree hyperparameters\n",
    "print(pipeline['gb'].get_params())\n",
    "gb_hyperparameters = {'gradientboostingclassifier__n_estimators': [100, 200,300], 'gradientboostingclassifier__max_depth': [1,2,3,4,5],'gradientboostingclassifier__learning_rate': [0.01,0.05,0.1,0.15,0.2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our hyperparameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {'l1':l1_hyperparameters, 'l2':l2_hyperparameters, 'rf':rf_hyperparameters,'gb':gb_hyperparameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fit and tune models with cross-validation\n",
    "\n",
    "Time to to tune our models with **cross-validation**.\n",
    "\n",
    "* The keys are the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries -  for ease of use. \n",
    "* The values are <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, we print <code style=\"color:crimson\">'{name} has been fitted.'</code> to track the progress.\n",
    "\n",
    "**HIGHLY IMPORTANT: It will take some time. Be patient, take a chill pill, look out the window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 has been fitted!\n",
      "l2 has been fitted!\n",
      "rf has been fitted!\n",
      "gb has been fitted!\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models to store our models tuned using cross-validation\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, algo in pipeline.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(algo, hyperparameters[name], cv=10)\n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    # Store model in fitted_models with appropriate key \n",
    "    fitted_models[name] = model\n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate metrics\n",
    "\n",
    "Time to evaluate our models and pick the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 best score: 0.848676026302\n",
      "l2 best score: 0.848676026302\n",
      "rf best score: 0.977785676204\n",
      "gb best score: 0.976363959481\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_ for each fitted model\n",
    "for name, model in fitted_models.items():\n",
    "    print(name, 'best score:', model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores are holdout accuracy scores. For classification problems, the default scoring metric is accuracy.\n",
    "- Accuracy is simply the percent of observations correctly classified by the model.\n",
    "\n",
    "However, straight accuracy is not always the best way to evaluate a classification model - if our target class is an imblanced class, then strongly predominant value might be positive, so even poor model's will score a \"high\" accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Area under ROC curve\n",
    "\n",
    "**Area under ROC curve** is a strong,reliable metric for classification tasks.\n",
    "\n",
    "Area under ROC curve is equivalent to the probability that a randomly chosen 'Left' observation ranks higher (has a higher predicted probability) than a randomly chosen 'Employed' observation.\n",
    "\n",
    "Basically, the ROC curve isa saying if you grabbed two observations and exactly one of them was the positive class and one of them was the negative class, what's the likelihood that your model can distinguish the two?\n",
    "- Since it's choosing one random positve and one random negative, it doesn't care about imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly lets take a look at our **confusion matrix** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict classes using L1-regularized logistic regression \n",
    "l1_pred = fitted_models['l1'].predict(X_test)\n",
    "# Display first 10 predictions for later comparison withtheir predicted probabalities\n",
    "l1_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1937</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1937  183\n",
       "1   266  428"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confusion matrix for y_test and pred\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, l1_pred))\n",
    "cm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so bueno....\n",
    "\n",
    "Our threshold of 0.5 seems to be miscallsifying many points. WE must find a best threshold that will maximize our model's TPR (True Positive Rate) and minimize it's FPR (False Positive Rate). AS well in predicting employee retention, there is no need to stress one classification or the other as in the case of terminal illness diagnostic.\n",
    "\n",
    "That why we use ze area under the ROC curve :)\n",
    "\n",
    "ROC curve:\n",
    "\n",
    "The ROC curve is a way to visualize the relationship between TPR (True Positive Rate) and FPR (False Positive Rate) across our model's threshold values.\n",
    "\n",
    "Lets calculate and plot our L1-regularized logistic regression model's ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.093680773747525981,\n",
       " 0.0015442983341427672,\n",
       " 0.010302337849146226,\n",
       " 0.72428475318602648,\n",
       " 0.79176777554682842,\n",
       " 0.052164626646663347,\n",
       " 0.040189205655579596,\n",
       " 0.028762396204263994,\n",
       " 0.061010721250835731,\n",
       " 0.28444946853333514]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict PROBABILITIES using L1-regularized logistic regression\n",
    "pred_l1 = fitted_models['l1'].predict_proba(X_test)\n",
    "\n",
    "# Get just the prediction for the positive class (1)\n",
    "pred_l1 = [pred[1] for pred in pred_l1]\n",
    "\n",
    "# Display first 10 predictions\n",
    "pred_l1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the ROC curve for L1-regularized logistic regression model using the <code style=\"color:steelblue\">roc_curve()</code> function that we imported earlier.\n",
    "\n",
    "<code style=\"color:steelblue\">roc_curve()</code> returns 3 lists of equal length:\n",
    "- False positive rates\n",
    "- True positive rates\n",
    "- And the thresholds at which the those were calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve from y_test and pred\n",
    "fpr, tpr, thresh = roc_curve(y_test, pred_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting into a data frame for convenience and look at the last 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>Thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.755660</td>\n",
       "      <td>0.994236</td>\n",
       "      <td>0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.783962</td>\n",
       "      <td>0.994236</td>\n",
       "      <td>0.008737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.783962</td>\n",
       "      <td>0.995677</td>\n",
       "      <td>0.008724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.995677</td>\n",
       "      <td>0.005025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.005015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.002521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.998559</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.935849</td>\n",
       "      <td>0.998559</td>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>0.935849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FPR       TPR  Thresholds\n",
       "606  0.755660  0.994236    0.010753\n",
       "607  0.783962  0.994236    0.008737\n",
       "608  0.783962  0.995677    0.008724\n",
       "609  0.852830  0.995677    0.005025\n",
       "610  0.852830  0.997118    0.005015\n",
       "611  0.915094  0.997118    0.002521\n",
       "612  0.915094  0.998559    0.002506\n",
       "613  0.935849  0.998559    0.001756\n",
       "614  0.935849  1.000000    0.001741\n",
       "615  1.000000  1.000000    0.000066"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store fpr, tpr, thresholds in DataFrame and display last 10\n",
    "roc = pd.DataFrame({'FPR': fpr, 'TPR': tpr, 'Thresholds': thresh})\n",
    "roc.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrease the threshold, both the false positive rate (no bueno) **and** the true positive rate (bueno) increase.\n",
    "\n",
    "Now, plotting our model's entire curve ROC curve  to visualize the relationship between TPR (True Positive Rate) and FPR (False Positive Rate) across our model's threshold values.\n",
    "\n",
    "Also plot an ROC curve of a hypothetical model that makes completely random predictions for heuristic reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c8a7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize figure\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='L1')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Diagonal 45 degree line\n",
    "# ROC curve of a completely random model\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "\n",
    "# Axes limits and labels\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we want our model's curve, the blue line, to sit as far above that dotted black line as possible.\n",
    "\n",
    "**AUROC : Aread Under ROC curve**\n",
    "or area under that blue line.\n",
    "\n",
    "- The AUROC for a completely random model will be 0.5 (worst case).\n",
    "- The maximum AUROC possible is 1.0.\n",
    "\n",
    "To calculate AUROC, we use the <code style=\"color:steelblue\">auc()</code> function we imported earlier in conjunction with the <code style=\"color:steelblue\">roc_curve()</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889708960905\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC curve again because repetition is the mother of learning\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_l1)\n",
    "# Calculate AUROC\n",
    "print( auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our L1-regularized logistic regression has a 88.97% chance of distinguishing between a positive observation and a negative one... not bad!\n",
    "\n",
    "That's the intuition behind AUROC.\n",
    "\n",
    "Calculating the AUROC for each of our fitted models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 : 0.889708960905\n",
      "l2 : 0.889710320265\n",
      "rf : 0.990653036811\n",
      "gb : 0.989602930781\n"
     ]
    }
   ],
   "source": [
    "# AUROC's of each of our fitted models\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict_proba(X_test)\n",
    "    pred2 = [p[1] for p in pred]\n",
    "    fpr, tpr, thresh = roc_curve(y_test, pred2)\n",
    "    print(name, ':', auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our random forest obtained the highest AUROC score as well as previously the highest cross-validation score after tuning our hyperparamters. Seems like Random forest is our best model.\n",
    "\n",
    "**Save the winning <code style=\"color:steelblue\">Pipeline</code> object into a pickle file.**\n",
    "* Save the <code style=\"color:steelblue\">fitted model</code>, not the <code style=\"color:steelblue\">GridSearchCV</code> object!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save winning model as final_model.pkl\n",
    "with open('project2_final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Recap: essential steps to training a model:\n",
    "* Split the dataset into training and test sets.\n",
    "* Set up model pipelines and hyperparameter grids.\n",
    "* Tune your models using cross-validation.\n",
    "* for classification, evaluate your models with the AUROC metric\n",
    "* And finally, save the winning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
